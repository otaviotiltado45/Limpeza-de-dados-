{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicia bibliotecas e local do arquivo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv('./vendas_modificado.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ff1cdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#verifica os tipos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf\u001b[49m.dtypes\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#verifica os tipos\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cfb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica os erros de digitação na coluna valor\n",
    "erros_valor = df[~df['valor'].str.replace('R$', '', regex=False).str.replace(',', '.').str.strip().str.match(r'^\\d+(\\.\\d+)?$')]\n",
    "\n",
    "\n",
    "print(erros_valor[['valor']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corige os erros dos valores\n",
    "df = df[df['valor'].str.replace('R$', '', regex=False).str.replace(',', '.').str.strip().str.match(r'^\\d+(\\.\\d+)?$')]\n",
    "\n",
    "df['valor'] = df['valor'].str.replace('R$', '', regex=False).str.replace(',', '.').astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbec31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padroniza data hora e frete\n",
    "df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
    "\n",
    "\n",
    "df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S', errors='coerce').dt.strftime('%H:%M:%S')\n",
    "\n",
    "df['frete'] = df['frete'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28884756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropa os nulos restantes \n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrige os valores nulos na coluna 'total' usando a fórmula correta\n",
    "faltando_total = df['total'].isna()\n",
    "df.loc[faltando_total, 'total'] = (df.loc[faltando_total, 'valor'] * df.loc[faltando_total, 'quantidade'] + df.loc[faltando_total, 'frete']).round(2)\n",
    "\n",
    "# Recalcula todos os valores de 'total' e padroniza com duas casas decimais\n",
    "df['total'] = (df['valor'] * df['quantidade'] + df['frete']).round(2)\n",
    "\n",
    "# Remove linhas com valores negativos nas colunas especificadas\n",
    "colunas = ['valor', 'quantidade', 'frete', 'total']\n",
    "df = df[(df[colunas] >= 0).all(axis=1)].reset_index(drop=True)\n",
    "\n",
    "# Exibe registros com discrepâncias\n",
    "print(df[['valor', 'quantidade', 'frete', 'total', ]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove resultados maiores que 999 objetivo é de manter todos os resultaods no maximoa té a casa dos cem\n",
    "df = df[df['total'] <= 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibe o data frame\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fed0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os status \n",
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa99ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confere se ainda existem nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo e padronizando os nomes dos status\n",
    "df['status'] = df['status'].replace({\n",
    "    'Pgto Confirmado': 'Pagamento Confirmado',\n",
    "    'aguardando pagamento': 'Aguardando Pagamento',\n",
    "    'Aguardando Pgto': 'Aguardando Pagamento',\n",
    "    'AP': 'Aguardando Pagamento',\n",
    "    'Sep': 'Em Separação',\n",
    "    'Separando': 'Em Separação',\n",
    "    'PC': 'Pagamento Confirmado',\n",
    "    'Entg': 'Entregue',\n",
    "    'Entregue com Sucesso': 'Entregue',\n",
    "    'Transp': 'Em Transporte',\n",
    "    'Transportando': 'Em Transporte'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando como ficou a distribuição dos status após a padronização\n",
    "df['status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688dbb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pagamento'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b84d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando produtos\n",
    "print(df['produto'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b895ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de correções: chaves = nomes errados / valores = nomes corretos\n",
    "correcoes_produtos = {\n",
    "    # Corrigindo com símbolos e variações comuns\n",
    "    'Pasta de Dente#$@!': 'Pasta de Dente',\n",
    "    'Queijo Mussarela#$@!': 'Queijo Mussarela',\n",
    "    'Sabonete#$@!': 'Sabonete',\n",
    "    'Manteiga#$@!': 'Manteiga',\n",
    "    'Café#$@!': 'Café',\n",
    "    'Açúcar#$@!': 'Açúcar',\n",
    "    'Desinfetante#$@!': 'Desinfetante',\n",
    "    'Papel Toalha#$@!': 'Papel Toalha',\n",
    "    'Condicionador#$@!': 'Condicionador',\n",
    "    'Molho de Tomate#$@!': 'Molho de Tomate',\n",
    "    'Água Mineral#$@!': 'Água Mineral',\n",
    "    'Refrigerante#$@!': 'Refrigerante',\n",
    "    'Presunto#$@!': 'Presunto',\n",
    "    'Cerveja#$@!': 'Cerveja',\n",
    "    'Biscoito Recheado#$@!': 'Biscoito Recheado',\n",
    "    'Macarrão#$@!': 'Macarrão',\n",
    "    'Óleo de Soja#$@!': 'Óleo de Soja',\n",
    "    'Vinho#$@!': 'Vinho',\n",
    "    'Sal#$@!': 'Sal',\n",
    "    'Suco de Laranja#$@!': 'Suco de Laranja',\n",
    "    'Shampoo#$@!': 'Shampoo',\n",
    "    'Farinha de Trigo#$@!': 'Farinha de Trigo',\n",
    "    'Detergente#$@!': 'Detergente',\n",
    "    'Pão de Forma#$@!': 'Pão de Forma',\n",
    "    'Arroz#$@!': 'Arroz',\n",
    "    'Feijão#$@!': 'Feijão',\n",
    "    'Amaciante#$@!': 'Amaciante',\n",
    "    'Leite Integral#$@!': 'Leite Integral',\n",
    "    'Papel Higiênico#$@!': 'Papel Higiênico',\n",
    "    'Sabão em Pó#$@!': 'Sabão em Pó',\n",
    "    'Carvão#$@!': 'Carvão',\n",
    "    'Condicioiador#$@!': 'Condicionador',\n",
    "\n",
    "    # Corrigindo erros de digitação\n",
    "    'Refrigkrante': 'Refrigerante',\n",
    "    'Scl': 'Sal',\n",
    "    'Papel qoalha': 'Papel Toalha',\n",
    "    'Desinfetanue': 'Desinfetante',\n",
    "    'Qbeijo Mussarela': 'Queijo Mussarela',\n",
    "    'Água Mineras': 'Água Mineral',\n",
    "    'Presuntd': 'Presunto',\n",
    "    'Macawrão': 'Macarrão',\n",
    "    'Sucoyde Laranja': 'Suco de Laranja',\n",
    "    'Clfé': 'Café',\n",
    "    'Desinfekante': 'Desinfetante',\n",
    "    'Majarrão': 'Macarrão',\n",
    "    'Cnfé': 'Café',\n",
    "    'Farinha de Tripo': 'Farinha de Trigo',\n",
    "    'Manteigt': 'Manteiga',\n",
    "    'zabonete': 'Sabonete',\n",
    "    'Mqcarrão': 'Macarrão',\n",
    "    'Arroc': 'Arroz',\n",
    "    'tal': 'Sal',\n",
    "    'Sabonepe': 'Sabonete',\n",
    "    'Papel Twalha': 'Papel Toalha',\n",
    "    'Água Mineual': 'Água Mineral',\n",
    "    'Condibionador': 'Condicionador',\n",
    "    'Caft': 'Café',\n",
    "    'ieijão': 'Feijão',\n",
    "    'Açúcaz': 'Açúcar',\n",
    "    'Amaciayte': 'Amaciante',\n",
    "    'Caff': 'Café',\n",
    "    'Mopho de Tomate': 'Molho de Tomate',\n",
    "    'Molmo de Tomate': 'Molho de Tomate',\n",
    "    'Biscoitq Recheado': 'Biscoito Recheado',\n",
    "    'Macirrão': 'Macarrão',\n",
    "    'Deqergente': 'Detergente',\n",
    "    'Cafc': 'Café',\n",
    "    'Queijo Mussarelz': 'Queijo Mussarela',\n",
    "    'Deterwente': 'Detergente',\n",
    "}\n",
    "\n",
    "# Aplicando as correções no DataFrame\n",
    "df['produto'] = df['produto'].replace(correcoes_produtos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aac8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando cidades\n",
    "df['cidade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a097d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando pais\n",
    "df['pais'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ec9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando marcas\n",
    "print(df['marca'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando clientes\n",
    "print(df['cliente'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove espaços das colunas , espaços extras dos valores\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.map(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d722a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibe o data frame\n",
    "df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4205225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropa duplicatas\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define uma função para validar o CEP\n",
    "def cep_valido(cep):\n",
    "    if isinstance(cep, str):\n",
    "        return bool(re.fullmatch(r\"\\d{5}-\\d{3}\", cep))\n",
    "    return False\n",
    "\n",
    "# Aplica o filtro\n",
    "df = df[df['cep'].apply(cep_valido)].reset_index(drop=True)\n",
    "\n",
    "# Formata os CEPs para o padrão 00000-000\n",
    "df['cep'] = df['cep'].astype(str).str.zfill(8).str.replace(r'(\\d{5})(\\d{3})', r'\\1-\\2', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978aea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma o data frame em csv\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "df.to_csv('vendas_tratado.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a5b72f",
   "metadata": {},
   "source": [
    "# Relatório de Limpeza e Padronização de Dados\n",
    "\n",
    "Durante o processo de análise e tratamento dos dados, diversos problemas que comprometiam a integridade e a qualidade das informações foram identificados e corrigidos. Essas ações visaram padronizar os formatos e assegurar que o conjunto de dados seja confiável para análises futuras. A seguir, apresenta-se um resumo detalhado das etapas realizadas:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Leitura e Inspeção Inicial\n",
    "\n",
    "- **Importação:** O arquivo `vendas_modificado.csv` foi importado utilizando a biblioteca `pandas`.\n",
    "- **Estrutura e Tipos de Dados:** Foram verificados os tipos de dados e a presença de valores nulos, o que permitiu identificar possíveis inconsistências iniciais.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Tratamento da Coluna `valor`\n",
    "\n",
    "- **Identificação de Erros:** Foram encontrados problemas de digitação e formatação, como a presença do símbolo `R$` e o uso de vírgula para separar decimais.\n",
    "- **Limpeza dos Dados:** As entradas que não correspondiam ao padrão esperado foram removidas.\n",
    "- **Conversão de Tipo:** Após a limpeza, os valores foram convertidos com sucesso para o tipo `float`.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Padronização de Datas, Horários e Valores de Frete\n",
    "\n",
    "- **Datas:** A coluna `data` foi convertida para o formato `datetime`, uniformizando a representação temporal.\n",
    "- **Horários:** A coluna `hora` foi ajustada para o padrão `HH:MM:SS`.\n",
    "- **Frete:** Os valores nulos na coluna `frete` foram substituídos por `0.0`, garantindo que os cálculos subsequentes não fossem comprometidos.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Correção da Coluna `total`\n",
    "\n",
    "- **Recalculo dos Valores:** Utilizando a fórmula `total = valor * quantidade + frete`, os valores ausentes foram recalculados.\n",
    "- **Padronização e Validação:** Todos os valores foram recalculados, arredondados para duas casas decimais, e linhas com valores negativos foram removidas para manter a coerência dos dados.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Eliminação de Duplicatas e Registros com Valores Faltantes\n",
    "\n",
    "- **Remoção de Valores Nulos Restantes:** Registros que ainda continham valores nulos após as etapas anteriores foram eliminados.\n",
    "- **Eliminação de Duplicatas:** Foram removidas entradas duplicadas para evitar redundâncias na base de dados.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Padronização dos Status de Pagamento\n",
    "\n",
    "- **Correção de Inconsistências:** A coluna `status` passava por diversas variações (por exemplo, _Pgto Confirmado_, _AP_, _aguardando pagamento_) que foram unificadas.\n",
    "- **Categorias Definidas:** Após a padronização, os status foram categorizados como:\n",
    "  - **Pagamento Confirmado**\n",
    "  - **Aguardando Pagamento**\n",
    "  - **Em Separação**\n",
    "  - **Em Transporte**\n",
    "  - **Entregue**\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Correção de Nomes de Produtos\n",
    "\n",
    "- **Padronização dos Nomes:** Muitos produtos apresentavam caracteres especiais ou erros de digitação. Um dicionário de correções foi criado para mapear os nomes errados para suas formas corretas.\n",
    "- **Resultado:** Essa etapa facilitou a análise das vendas, possibilitando uma identificação precisa dos produtos.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Análise das Informações Complementares\n",
    "\n",
    "- **Verificações:** Foram analisadas outras colunas, como `cidade`, `país`, `marca` e `cliente`, para assegurar a consistência dos dados.\n",
    "- **Ajustes de Formatação:** Foram removidos espaços extras nos nomes das colunas e nos valores, garantindo a padronização.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Validação e Formatação de CEP\n",
    "\n",
    "- **Validação do CEP:** Uma função foi criada para validar se os CEPs obedecem o padrão `00000-000`.\n",
    "- **Ajuste de Formato:** Os CEPs foram formatados e validados, assegurando a integridade dos dados de localização.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "**Resultado Final:**\n",
    "\n",
    "- **Consistência dos Dados:** Todos os tipos e formatos foram padronizados.\n",
    "- **Cálculos Precisos:** Os valores foram recalculados e validados, garantindo a precisão de campos como `total`.\n",
    "- **Eliminação de Inconsistências:** Dados nulos, duplicados e inconsistências em nomes foram completamente eliminados ou corrigidos.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
